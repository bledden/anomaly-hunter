# Anomaly Hunter - System Architecture Diagrams
## Visual Architecture Guide for Demo & Documentation

These diagrams illustrate the multi-agent architecture, data flow, and integration ecosystem.

---

## [01] High-Level Architecture (Simple Overview)

**Use this for:** Initial demo introduction, investor presentations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CLI / API Entry Point                      â”‚
â”‚              python3 cli.py detect data.csv                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ORCHESTRATOR (Brain)                           â”‚
â”‚        Coordinates 3 Agents + Synthesis Layer                â”‚
â”‚     Based on Corch Sequential Collaboration (73% quality)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                     â”‚
        â–¼                 â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Pattern       â”‚  â”‚Change        â”‚  â”‚Root Cause        â”‚
â”‚Analyst       â”‚  â”‚Detective     â”‚  â”‚Agent             â”‚
â”‚              â”‚  â”‚              â”‚  â”‚                  â”‚
â”‚GPT-5 Pro     â”‚  â”‚Claude 4.5    â”‚  â”‚Claude 4.5        â”‚
â”‚via StackAI   â”‚  â”‚Sonnet        â”‚  â”‚Sonnet            â”‚
â”‚              â”‚  â”‚              â”‚  â”‚                  â”‚
â”‚Statistical   â”‚  â”‚Time-series   â”‚  â”‚Dependency        â”‚
â”‚Z-score       â”‚  â”‚Drift         â”‚  â”‚Graph             â”‚
â”‚Baseline      â”‚  â”‚Changepoint   â”‚  â”‚Hypothesis        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   SYNTHESIS (Confidence-Weighted)  â”‚
        â”‚   â€¢ Vote on severity (1-10)        â”‚
        â”‚   â€¢ Aggregate anomaly indices      â”‚
        â”‚   â€¢ Generate recommendation        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    AUTONOMOUS LEARNING ENGINE      â”‚
        â”‚   â€¢ Track agent performance        â”‚
        â”‚   â€¢ Adjust confidence weights      â”‚
        â”‚   â€¢ Store successful strategies    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         SPONSOR INTEGRATIONS       â”‚
        â”‚  Weave â”‚ Sentry â”‚ Senso â”‚ Redpanda â”‚
        â”‚  (Observability â”‚ Monitoring â”‚ RAG) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Talking Points:**
- "Three specialized agents run in parallel, each with different expertise"
- "Orchestrator synthesizes findings using confidence-weighted voting"
- "Autonomous learning adjusts weights based on historical accuracy"
- "9 sponsor integrations provide observability, monitoring, and knowledge base"

---

## [02] Multi-Agent Collaboration Flow (Detailed)

**Use this for:** Technical deep-dive on agent architecture

```
USER DATA INPUT (CSV)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
timestamp,value
2024-10-21T00:00:00,100
2024-10-21T01:00:00,102
2024-10-21T02:00:00,450  â† Anomaly
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ORCHESTRATOR.investigate(context)                        â”‚
â”‚  Input: AnomalyContext(data, timestamps, metadata)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 1       â”‚ â”‚ AGENT 2       â”‚ â”‚ AGENT 3        â”‚
â”‚Pattern Analystâ”‚ â”‚Change Detectiveâ”‚ â”‚Root Cause     â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                 â”‚                 â”‚
    â”‚ [Parallel Execution - asyncio.gather()]
    â”‚                 â”‚                 â”‚
    â–¼                 â–¼                 â–¼

AGENT 1: Pattern Analyst (GPT-5 Pro)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Step 1: Statistical Analysis
  â€¢ Calculate: mean=100, std=10, median=100
  â€¢ Z-scores: [0, 0.2, ..., 35.0]  â† Index 2 is 35Ïƒ!
  â€¢ Detect anomalies: z > 3Ïƒ threshold
  â€¢ Result: 1 anomaly at index 2

Step 2: LLM Analysis (via StackAI)
  Prompt:
    "You are a Pattern Analyst...
     Data: mean=100, std=10
     Anomalies: 1 point at 35Ïƒ deviation
     Assess severity (1-10) and describe pattern."

  Response:
    "Severity: 9
     Pattern: Extreme spike - 35 standard deviations
     Impact: Critical outlier, likely system fault"

Step 3: Return Finding
  {
    "agent_name": "pattern_analyst",
    "finding": "1 anomaly detected. Extreme spike. Top deviation: 35.0Ïƒ",
    "confidence": 0.9,  â† High z-score = high confidence
    "severity": 9,
    "evidence": {
      "anomaly_indices": [2],
      "z_scores": [(2, 35.0)],
      "statistical_summary": "Mean: 100, Std: 10, 1 anomaly"
    }
  }

AGENT 2: Change Detective (Claude 4.5 Sonnet)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Step 1: Drift Detection
  â€¢ Compute baseline: first 50% of data
  â€¢ Compute recent: last 50% of data
  â€¢ Drift = abs(recent_mean - baseline_mean) / baseline_mean
  â€¢ Result: 175% drift (baseline=100, recent=184)

Step 2: Changepoint Detection
  â€¢ Segment data into windows
  â€¢ CUSUM algorithm for changepoint detection
  â€¢ Result: Changepoint at index 2

Step 3: LLM Analysis
  Prompt:
    "You are a Change Detective...
     Detected 175% drift and changepoint at index 2
     Assess time-series stability."

  Response:
    "Severity: 10
     Pattern: Sudden regime shift at timestamp 2
     Impact: System entered new operational state"

Step 4: Return Finding
  {
    "agent_name": "change_detective",
    "finding": "175% drift detected. Changepoint at index 2.",
    "confidence": 1.0,  â† Clear drift signal
    "severity": 10,
    "evidence": {
      "anomaly_indices": [2],
      "drift_percentage": 175.0,
      "changepoint_index": 2
    }
  }

AGENT 3: Root Cause Agent (Claude 4.5 Sonnet)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Step 1: Context Retrieval (Senso RAG)
  â€¢ Query Senso knowledge base for similar anomalies
  â€¢ Result: "Previous spike in financial data due to flash crash"

Step 2: LLM Root Cause Hypothesis
  Prompt:
    "You are a Root Cause Agent...
     Data shows extreme spike at index 2
     Historical context: flash crash patterns
     Generate 3 hypotheses for root cause."

  Response:
    "Severity: 7
     Hypotheses:
     1. Data pipeline error (missing validation)
     2. External shock event (market crash)
     3. Sensor malfunction
     Likely: Pipeline error given 450 is exactly 4.5x baseline"

Step 3: Return Finding
  {
    "agent_name": "root_cause",
    "finding": "Root cause likely: Pipeline error (4.5x multiplier pattern)",
    "confidence": 0.7,  â† Hypothesis, not certainty
    "severity": 7,
    "evidence": {
      "anomaly_indices": [2],
      "hypotheses": ["Pipeline error", "External shock", "Sensor fault"],
      "senso_context": "Flash crash pattern detected"
    }
  }

        â”‚               â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SYNTHESIS LAYER (Confidence-Weighted Voting)            â”‚
â”‚                                                           â”‚
â”‚  Input: 3 AgentFindings                                  â”‚
â”‚    - Pattern: severity=9, confidence=0.9                 â”‚
â”‚    - Change:  severity=10, confidence=1.0                â”‚
â”‚    - Root:    severity=7, confidence=0.7                 â”‚
â”‚                                                           â”‚
â”‚  Step 1: Compute Adaptive Weights (from learning)        â”‚
â”‚    - pattern_analyst: historical accuracy = 0.85         â”‚
â”‚    - change_detective: historical accuracy = 0.92        â”‚
â”‚    - root_cause: historical accuracy = 0.78              â”‚
â”‚                                                           â”‚
â”‚  Step 2: Weighted Severity Calculation                   â”‚
â”‚    weight_1 = 0.9 * (0.5 + 0.5*0.85) = 0.83              â”‚
â”‚    weight_2 = 1.0 * (0.5 + 0.5*0.92) = 0.96              â”‚
â”‚    weight_3 = 0.7 * (0.5 + 0.5*0.78) = 0.62              â”‚
â”‚                                                           â”‚
â”‚    weighted_severity = (9*0.83 + 10*0.96 + 7*0.62)       â”‚
â”‚                       / (0.83 + 0.96 + 0.62)             â”‚
â”‚                     = 8.9 â†’ rounds to 9                  â”‚
â”‚                                                           â”‚
â”‚  Step 3: Aggregate Anomaly Indices (union)               â”‚
â”‚    all_indices = {2, 2, 2} â†’ [2]                         â”‚
â”‚                                                           â”‚
â”‚  Step 4: Generate Summary                                â”‚
â”‚    "pattern_analyst: 1 anomaly. Extreme spike. 35Ïƒ |     â”‚
â”‚     change_detective: 175% drift. Changepoint at 2 |     â”‚
â”‚     root_cause: Pipeline error (4.5x multiplier)"        â”‚
â”‚                                                           â”‚
â”‚  Step 5: Generate Recommendation                         â”‚
â”‚    Severity 9 â†’ "ğŸš¨ CRITICAL: Immediate action required" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AUTONOMOUS LEARNING (Post-Detection)                    â”‚
â”‚                                                           â”‚
â”‚  â€¢ Update total_detections: 62 â†’ 63                      â”‚
â”‚  â€¢ Update per-agent stats:                               â”‚
â”‚    - pattern_analyst.total += 1                          â”‚
â”‚    - change_detective.total += 1                         â”‚
â”‚    - root_cause.total += 1                               â”‚
â”‚  â€¢ Store successful strategy (confidence > 0.85):        â”‚
â”‚    - Pattern: 3-agent agreement, severity 9              â”‚
â”‚    - Approach: "Extreme spike with drift confirmation"   â”‚
â”‚  â€¢ Save to cache/learning/agent_performance.json         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTPUT: AnomalyVerdict                                  â”‚
â”‚  {                                                        â”‚
â”‚    "severity": 9,                                        â”‚
â”‚    "confidence": 0.87,  â† Average(0.9, 1.0, 0.7)         â”‚
â”‚    "anomalies_detected": [2],                            â”‚
â”‚    "summary": "pattern_analyst: 1 anomaly...",           â”‚
â”‚    "recommendation": "ğŸš¨ CRITICAL: Immediate action...", â”‚
â”‚    "timestamp": "2024-10-21T02:15:00Z"                   â”‚
â”‚  }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Talking Points:**
- "Each agent analyzes the same data independently - no confirmation bias"
- "Synthesis uses both agent confidence AND historical accuracy"
- "Learning engine adjusts weights after every detection - continuous improvement"
- "Final verdict combines all evidence with actionable recommendation"

---

## [03] Autonomous Learning Loop

**Use this for:** Explaining self-improvement capabilities

```
AUTONOMOUS LEARNING CYCLE (60+ Detections Processed)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DETECTION #1 (Initial - No Learning)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Agent Weights: All equal (0.33 each)         â”‚   â”‚
â”‚  â”‚ Pattern: 0.33 â”‚ Change: 0.33 â”‚ Root: 0.33   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  Result: Severity 7, Confidence 0.65               â”‚
â”‚  User Feedback: "False positive - normal variance"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LEARNING UPDATE                                     â”‚
â”‚  â€¢ pattern_analyst: correct=0, total=1, acc=0%       â”‚
â”‚  â€¢ change_detective: correct=0, total=1, acc=0%      â”‚
â”‚  â€¢ root_cause: correct=0, total=1, acc=0%            â”‚
â”‚  (No feedback yet, use conservative weights)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DETECTION #10 (Some Learning)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Adaptive Weights (from 9 prior detections):  â”‚   â”‚
â”‚  â”‚ Pattern: 0.28 â”‚ Change: 0.42 â”‚ Root: 0.30   â”‚   â”‚
â”‚  â”‚ â†‘ Change Detective performing best           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  Result: Severity 8, Confidence 0.78               â”‚
â”‚  User Feedback: "True positive - good catch"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LEARNING UPDATE                                     â”‚
â”‚  â€¢ pattern_analyst: correct=6, total=10, acc=60%     â”‚
â”‚  â€¢ change_detective: correct=9, total=10, acc=90%    â”‚
â”‚  â€¢ root_cause: correct=7, total=10, acc=70%          â”‚
â”‚  â€¢ Store strategy: "Drift + spike = high severity"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DETECTION #62 (Current - Mature Learning)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Adaptive Weights (from 61 prior detections): â”‚   â”‚
â”‚  â”‚ Pattern: 0.31 â”‚ Change: 0.46 â”‚ Root: 0.23   â”‚   â”‚
â”‚  â”‚ â†‘ Change Detective weighted highest          â”‚   â”‚
â”‚  â”‚ â†“ Root Cause weighted lowest (less accurate) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  Result: Severity 9, Confidence 0.87               â”‚
â”‚  âœ“ Improvement: +0.22 confidence from detection #1  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LEARNING METRICS (After 62 Detections):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pattern Analyst                      â”‚
â”‚ â€¢ Accuracy: 85%                      â”‚
â”‚ â€¢ Avg Confidence: 0.82               â”‚
â”‚ â€¢ Best at: Spike detection           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Change Detective                     â”‚
â”‚ â€¢ Accuracy: 92%  â† Highest!          â”‚
â”‚ â€¢ Avg Confidence: 0.91               â”‚
â”‚ â€¢ Best at: Drift, regime shift       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Root Cause Agent                     â”‚
â”‚ â€¢ Accuracy: 78%                      â”‚
â”‚ â€¢ Avg Confidence: 0.73               â”‚
â”‚ â€¢ Best at: Hypothesis generation     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STORED STRATEGIES (Top 3 of 100):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. "Drift + spike + high z-score â†’ Severity 9-10" (confidence: 0.92)
2. "Gradual drift only â†’ Severity 5-7" (confidence: 0.85)
3. "Single outlier, no drift â†’ Severity 3-5" (confidence: 0.88)
```

**Talking Points:**
- "System learns from every detection - 62 processed so far"
- "Change Detective has proven most accurate (92%) - gets higher weight"
- "Confidence improved +0.22 (34% relative) from initial detections"
- "Stores successful strategies for pattern matching"

---

## [04] Sponsor Integration Ecosystem

**Use this for:** Showcasing production readiness and sponsor value

```
ANOMALY HUNTER INTEGRATION ARCHITECTURE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  CORE ORCHESTRATOR  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
        â–¼                  â–¼                  â–¼
   [LLM Layer]    [Observability]    [Production Ops]


[1] LLM ROUTING & EXECUTION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI (Sponsor 1)                                â”‚
â”‚  â€¢ GPT-5 Pro for Pattern Analyst                   â”‚
â”‚  â€¢ Direct API: openai.chat.completions.create()    â”‚
â”‚  â€¢ Used when: StackAI flows disabled               â”‚
â”‚  Value: Primary LLM provider, statistical analysis â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  StackAI (Sponsor 2)                               â”‚
â”‚  â€¢ Multi-model gateway for all 3 agents            â”‚
â”‚  â€¢ Flow IDs:                                       â”‚
â”‚    - 68f2c162c148d3edaa517114 (Claude 4.5 Sonnet)  â”‚
â”‚  â€¢ Used when: STACKAI_API_KEY set                  â”‚
â”‚  Value: Centralized routing, cost tracking, flows  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TrueFoundry (Sponsor 3)                           â”‚
â”‚  â€¢ ML platform for model deployment                â”‚
â”‚  â€¢ Metrics: detection_count, avg_confidence        â”‚
â”‚  â€¢ Used when: TRUEFOUNDRY_API_KEY set              â”‚
â”‚  Value: Production ML ops, model versioning        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


[2] OBSERVABILITY & MONITORING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Weave (Sponsor 9) - LLM Observability             â”‚
â”‚  â€¢ Traces every LLM call (agents + orchestrator)   â”‚
â”‚  â€¢ Tracks: prompts, tokens, latency, cost          â”‚
â”‚  â€¢ Nested traces: investigate() â†’ 3 agents         â”‚
â”‚  â€¢ Used when: WEAVE_ENABLED=true                   â”‚
â”‚  Value: Debug LLM behavior, optimize prompts       â”‚
â”‚                                                     â”‚
â”‚  Example Trace:                                    â”‚
â”‚    investigate()          [2.3s, 3500 tokens]      â”‚
â”‚    â”œâ”€ pattern_analyst()   [0.8s, 1200 tokens]      â”‚
â”‚    â”œâ”€ change_detective()  [0.7s, 1100 tokens]      â”‚
â”‚    â””â”€ root_cause()        [0.8s, 1200 tokens]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sentry (Sponsor 4) - Error Monitoring             â”‚
â”‚  â€¢ Captures all detections as events               â”‚
â”‚  â€¢ Severity >= 7 â†’ WARNING level                   â”‚
â”‚  â€¢ Severity < 7 â†’ INFO level                       â”‚
â”‚  â€¢ Context: severity, confidence, anomaly_count    â”‚
â”‚  â€¢ Used when: SENTRY_DSN set                       â”‚
â”‚  Value: Production monitoring, alerting, debugging â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


[3] KNOWLEDGE & CONTEXT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Senso (Sponsor 8) - RAG Knowledge Base            â”‚
â”‚  â€¢ Retrieves historical anomaly patterns           â”‚
â”‚  â€¢ Query: "spike in financial data"                â”‚
â”‚  â€¢ Returns: Top 3 similar cases from history       â”‚
â”‚  â€¢ Provides context to Root Cause Agent            â”‚
â”‚  â€¢ Used when: SENSO_API_KEY + SENSO_ORG_ID set     â”‚
â”‚  Value: Learn from history, avoid repeated issues  â”‚
â”‚                                                     â”‚
â”‚  Flow:                                             â”‚
â”‚    Root Cause Agent â†’ Senso.retrieve_context()     â”‚
â”‚                    â†’ "Flash crash pattern detected"â”‚
â”‚                    â†’ Include in LLM prompt         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


[4] STREAMING & NOTIFICATIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redpanda (Sponsor 5) - Event Streaming            â”‚
â”‚  â€¢ Publishes detections to Kafka-compatible topic  â”‚
â”‚  â€¢ Topic: anomaly-detections                       â”‚
â”‚  â€¢ Format: JSON with verdict + metadata            â”‚
â”‚  â€¢ Used when: REDPANDA_BROKER set                  â”‚
â”‚  Value: Real-time alerting, downstream consumers   â”‚
â”‚                                                     â”‚
â”‚  Event Example:                                    â”‚
â”‚    {                                               â”‚
â”‚      "severity": 9,                                â”‚
â”‚      "timestamp": "2024-10-21T02:15:00Z",          â”‚
â”‚      "anomalies": [2],                             â”‚
â”‚      "summary": "Critical spike detected"          â”‚
â”‚    }                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ElevenLabs (Sponsor 6) - Voice Synthesis          â”‚
â”‚  â€¢ Generates audio alerts for critical detections  â”‚
â”‚  â€¢ Severity >= 8 â†’ Voice notification              â”‚
â”‚  â€¢ Model: eleven_turbo_v2_5                        â”‚
â”‚  â€¢ Used when: ELEVENLABS_API_KEY set               â”‚
â”‚  Value: Audio alerts for on-call engineers         â”‚
â”‚                                                     â”‚
â”‚  Example:                                          â”‚
â”‚    Input: "Critical anomaly: 9/10 severity"        â”‚
â”‚    Output: anomaly_alert_20241021.mp3              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


[5] WORKFLOW AUTOMATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Airia (Sponsor 7) - Workflow Orchestration        â”‚
â”‚  â€¢ Triggers automated workflows on detection       â”‚
â”‚  â€¢ Workflow: "Critical Detection Response"         â”‚
â”‚    1. Log to incident tracker                      â”‚
â”‚    2. Alert on-call engineer (PagerDuty)           â”‚
â”‚    3. Create Jira ticket                           â”‚
â”‚    4. Run automated diagnostics                    â”‚
â”‚  â€¢ Used when: AIRIA_API_KEY set                    â”‚
â”‚  Value: Automated incident response, no manual workâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


INTEGRATION STATUS (9/9 Active):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[OK] OpenAI       - Primary LLM provider
[OK] StackAI      - Multi-model routing
[OK] TrueFoundry  - ML platform metrics
[OK] Sentry       - Error monitoring
[OK] Redpanda     - Event streaming
[OK] ElevenLabs   - Voice alerts
[OK] Airia        - Workflow automation
[OK] Senso        - RAG knowledge base
[OK] Weave        - LLM observability
```

**Talking Points:**
- "9 sponsor integrations - all production-ready and tested"
- "Weave provides full LLM observability - see every token, every prompt"
- "Sentry captures all detections for production monitoring"
- "Senso RAG learns from history - no repeated incidents"
- "Complete end-to-end: detection â†’ streaming â†’ alerting â†’ workflow"

---

## [05] Data Flow: From CSV to Verdict

**Use this for:** Demo walkthrough, explaining what happens under the hood

```
COMPLETE DATA FLOW EXAMPLE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[Step 1] USER PROVIDES CSV
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
$ python3 cli.py detect demo/financial_fraud.csv

File: demo/financial_fraud.csv
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
timestamp,value
2024-10-21T00:00:00,85.23
2024-10-21T01:00:00,92.17
2024-10-21T02:00:00,1250.00  â† FRAUD!
2024-10-21T03:00:00,88.45
        â”‚
        â–¼

[Step 2] DATA PARSING & VALIDATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLI Parser                       â”‚
â”‚ â€¢ Read CSV with pandas           â”‚
â”‚ â€¢ Extract 'value' column         â”‚
â”‚ â€¢ Extract 'timestamp' column     â”‚
â”‚ â€¢ Validate: 100 rows, 2 columns  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AnomalyContext Creation          â”‚
â”‚ â€¢ data: [85.23, 92.17, 1250, ...]â”‚
â”‚ â€¢ timestamps: ['2024-10-21...']  â”‚
â”‚ â€¢ metadata: {"source": "csv"}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼

[Step 3] ORCHESTRATOR INITIALIZATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AnomalyOrchestrator.__init__()   â”‚
â”‚ â€¢ Load 3 agents                  â”‚
â”‚ â€¢ Initialize AutonomousLearner   â”‚
â”‚ â€¢ Connect to Weave (if enabled)  â”‚
â”‚ â€¢ Connect to Sentry              â”‚
â”‚ Output:                          â”‚
â”‚   [OK] Loaded 3 agents           â”‚
â”‚   [LEARNING] 62 detections       â”‚
â”‚   [WEAVE] Tracing enabled        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼

[Step 4] SENSO RAG CONTEXT RETRIEVAL
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SensoRAG.retrieve_context()      â”‚
â”‚ Query: "financial fraud spike"   â”‚
â”‚                                  â”‚
â”‚ API Call:                        â”‚
â”‚   POST https://sdk.senso.ai/...  â”‚
â”‚   {                              â”‚
â”‚     "query": "fraud spike",      â”‚
â”‚     "top_k": 3                   â”‚
â”‚   }                              â”‚
â”‚                                  â”‚
â”‚ Response:                        â”‚
â”‚   {                              â”‚
â”‚     "cases": [                   â”‚
â”‚       "2024-09-15: Card fraud    â”‚
â”‚        detected via 5Ïƒ spike",   â”‚
â”‚       "2024-08-03: Account       â”‚
â”‚        takeover pattern"         â”‚
â”‚     ]                            â”‚
â”‚   }                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼

[Step 5] PARALLEL AGENT EXECUTION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
asyncio.gather([
  pattern_analyst.analyze(),
  change_detective.analyze(),
  root_cause.analyze()
])
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼              â–¼
   [Agent 1]      [Agent 2]     [Agent 3]
   0.8s exec      0.7s exec     0.8s exec
        â”‚             â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                Total: 0.8s (parallel!)
                      â”‚
                      â–¼

[Step 6] WEAVE TRACING (Optional)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Weave Trace Visualization        â”‚
â”‚                                  â”‚
â”‚ investigate()          [2.3s]    â”‚
â”‚ â”œâ”€ pattern_analyst()   [0.8s]    â”‚
â”‚ â”‚  â”œâ”€ Input: data=[85, 92, ...]  â”‚
â”‚ â”‚  â”œâ”€ Output: severity=9         â”‚
â”‚ â”‚  â””â”€ Tokens: 1200               â”‚
â”‚ â”œâ”€ change_detective()  [0.7s]    â”‚
â”‚ â”‚  â”œâ”€ Input: data=[85, 92, ...]  â”‚
â”‚ â”‚  â”œâ”€ Output: severity=10        â”‚
â”‚ â”‚  â””â”€ Tokens: 1100               â”‚
â”‚ â””â”€ root_cause()        [0.8s]    â”‚
â”‚    â”œâ”€ Input: data=[85, 92, ...]  â”‚
â”‚    â”œâ”€ Output: severity=7         â”‚
â”‚    â””â”€ Tokens: 1200               â”‚
â”‚                                  â”‚
â”‚ Total Tokens: 3500               â”‚
â”‚ Total Cost: $0.12                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼

[Step 7] SYNTHESIS & VERDICT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Orchestrator._synthesize()       â”‚
â”‚ â€¢ Adaptive weights from learning â”‚
â”‚ â€¢ Weighted severity: 8.9 â†’ 9     â”‚
â”‚ â€¢ Anomaly indices: [2]           â”‚
â”‚ â€¢ Avg confidence: 0.87           â”‚
â”‚ â€¢ Recommendation: "ğŸš¨ CRITICAL"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼

[Step 8] AUTONOMOUS LEARNING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AutonomousLearner.learn()        â”‚
â”‚ â€¢ Update total: 62 â†’ 63          â”‚
â”‚ â€¢ Update agent stats             â”‚
â”‚ â€¢ Store strategy (conf > 0.85)   â”‚
â”‚ â€¢ Save to cache/learning/...json â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼

[Step 9] SPONSOR INTEGRATIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sentry Event                     â”‚
â”‚ â€¢ Level: WARNING (severity >= 7) â”‚
â”‚ â€¢ Message: "Anomaly: 9/10"       â”‚
â”‚ â€¢ Context: {severity: 9, ...}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redpanda Stream (if enabled)     â”‚
â”‚ â€¢ Topic: anomaly-detections      â”‚
â”‚ â€¢ Payload: {severity: 9, ...}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Airia Workflow (if severity >= 8)â”‚
â”‚ â€¢ Trigger: "Critical Detection"  â”‚
â”‚ â€¢ Actions: Alert + Ticket        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼

[Step 10] CLI OUTPUT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ANOMALY HUNTER - Detection Results
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Severity: 9/10 ğŸš¨ CRITICAL
Confidence: 87%
Anomalies Detected: 1 point
Indices: [2]

Agent Findings:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[Pattern Analyst] 87Ïƒ deviation - extreme fraud pattern
[Change Detective] 1370% drift - account takeover
[Root Cause] Likely: Stolen credentials + large transfer

Recommendation:
ğŸš¨ CRITICAL: Immediate action required.
Alert on-call team, freeze account, investigate source.

Total Time: 2.3s
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TOTAL LATENCY BREAKDOWN:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ CSV parse:           10ms
â€¢ Senso context:       80ms (network)
â€¢ Agent execution:    800ms (parallel LLM calls)
â€¢ Synthesis:            5ms
â€¢ Learning update:     10ms
â€¢ Sponsor integrations: 50ms (async)
â€¢ Output formatting:    5ms
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TOTAL:                960ms (~1 second)
```

**Talking Points:**
- "End-to-end detection in under 1 second"
- "Agents run in parallel - not sequential (would be 2.4s otherwise)"
- "Senso provides historical context before analysis"
- "Weave captures full trace - see every LLM call, every token"
- "Sentry + Redpanda + Airia handle production response automatically"

---

## [06] Multi-Domain Validation Results

**Use this for:** Showcasing domain-agnostic capabilities

```
COMPREHENSIVE DOMAIN EVALUATION RESULTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Test Suite: evaluations/comprehensive_evaluator.py
Total Scenarios: 15 (5 domains Ã— 3 scenarios)
Detection Rate: 100% (15/15 detected)
Avg Confidence: 75.6%
Avg Detection Time: 0.022s


[Domain 1] FINANCIAL SERVICES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Scenario 1.1: Credit Card Fraud
  Data: 100 transactions over 4 days
  Normal: $20-$200, mean ~$80
  Anomaly: 5 fraudulent charges ($850-$1250)

  Result:
    [OK] Detected: 5/5 anomalies
    Severity: 8/10
    Confidence: 87%
    Pattern: "87.2Ïƒ deviation - extreme fraud pattern"
    Time: 18ms

Scenario 1.2: Flash Crash
  Data: 100 stock prices over trading day
  Normal: $145-$155
  Anomaly: Sudden drop to $95 (35% crash)

  Result:
    [OK] Detected: 8 anomalies
    Severity: 9/10
    Confidence: 82%
    Pattern: "Rapid drawdown - market shock event"
    Time: 22ms

Scenario 1.3: Account Takeover
  Data: Login frequency (hourly)
  Normal: 2-5 logins/hour
  Anomaly: 45 logins in 1 hour (credential stuffing)

  Result:
    [OK] Detected: 1 anomaly
    Severity: 7/10
    Confidence: 71%
    Pattern: "Burst activity - potential bot attack"
    Time: 19ms

Domain Summary:
  Detection Rate: 3/3 (100%)
  Avg Confidence: 80.0%
  Avg Severity: 8.0/10


[Domain 2] IOT MANUFACTURING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Scenario 2.1: Equipment Bearing Failure
  Data: Vibration sensor (5-min intervals)
  Normal: 1.2 mm/s
  Anomaly: Progressive degradation to 8-9 mm/s

  Result:
    [OK] Detected: 12 anomalies
    Severity: 9/10
    Confidence: 83%
    Pattern: "Gradual drift + spike - bearing wear"
    Time: 24ms

Scenario 2.2: Temperature Overheat
  Data: Motor temperature (Â°C)
  Normal: 65-75Â°C
  Anomaly: Climb to 110Â°C (thermal shutdown risk)

  Result:
    [OK] Detected: 8 anomalies
    Severity: 8/10
    Confidence: 79%
    Pattern: "Threshold breach - cooling failure"
    Time: 21ms

Scenario 2.3: Pressure Leak
  Data: Hydraulic pressure (PSI)
  Normal: 2000 PSI Â±50
  Anomaly: Drop to 1500 PSI (25% loss)

  Result:
    [OK] Detected: 5 anomalies
    Severity: 7/10
    Confidence: 68%
    Pattern: "Sustained drop - leak detected"
    Time: 20ms

Domain Summary:
  Detection Rate: 3/3 (100%)
  Avg Confidence: 76.7%
  Avg Severity: 8.0/10


[Domain 3] HEALTHCARE MONITORING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Scenario 3.1: Hypoglycemia Event
  Data: Blood glucose (mg/dL, 15-min intervals)
  Normal: 80-140 mg/dL
  Anomaly: Drop to 45 mg/dL (critical <70)

  Result:
    [OK] Detected: 3 anomalies
    Severity: 6/10
    Confidence: 68%
    Pattern: "Below threshold - hypoglycemic episode"
    Time: 25ms

Scenario 3.2: Tachycardia
  Data: Heart rate (BPM)
  Normal: 60-100 BPM
  Anomaly: Sustained 140+ BPM (tachycardia)

  Result:
    [OK] Detected: 7 anomalies
    Severity: 7/10
    Confidence: 72%
    Pattern: "Elevated baseline - cardiac stress"
    Time: 23ms

Scenario 3.3: Hypertensive Crisis
  Data: Blood pressure (mmHg)
  Normal: 120/80 Â±10
  Anomaly: Spike to 190/110 (emergency)

  Result:
    [OK] Detected: 4 anomalies
    Severity: 8/10
    Confidence: 63%
    Pattern: "Critical threshold - hypertensive crisis"
    Time: 26ms

Domain Summary:
  Detection Rate: 3/3 (100%)
  Avg Confidence: 67.8%
  Avg Severity: 7.0/10


[Domain 4] DEVOPS MONITORING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Scenario 4.1: API Latency Spike
  Data: Response time (ms, per minute)
  Normal: 90ms
  Anomaly: Degradation to 2100ms (23x slower)

  Result:
    [OK] Detected: 8 anomalies
    Severity: 9/10
    Confidence: 87%
    Pattern: "2233% increase - database contention"
    Time: 19ms

Scenario 4.2: Memory Leak
  Data: Heap usage (MB)
  Normal: 512MB Â±50
  Anomaly: Gradual growth to 1800MB (OOM crash imminent)

  Result:
    [OK] Detected: 15 anomalies
    Severity: 8/10
    Confidence: 84%
    Pattern: "Linear growth - memory leak detected"
    Time: 22ms

Scenario 4.3: Error Rate Surge
  Data: Errors per minute
  Normal: 2-5 errors/min
  Anomaly: Spike to 150 errors/min (30x increase)

  Result:
    [OK] Detected: 6 anomalies
    Severity: 9/10
    Confidence: 76%
    Pattern: "Exponential increase - cascading failure"
    Time: 20ms

Domain Summary:
  Detection Rate: 3/3 (100%)
  Avg Confidence: 82.2%
  Avg Severity: 8.7/10


[Domain 5] E-COMMERCE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Scenario 5.1: Conversion Rate Drop
  Data: Hourly conversion rate (%)
  Normal: 3.5-4.5%
  Anomaly: Drop to 1.2% (checkout bug)

  Result:
    [OK] Detected: 5 anomalies
    Severity: 7/10
    Confidence: 73%
    Pattern: "Sharp decline - checkout flow broken"
    Time: 21ms

Scenario 5.2: Cart Abandonment Spike
  Data: Abandonment rate (%)
  Normal: 65-70%
  Anomaly: Spike to 92% (payment processor down)

  Result:
    [OK] Detected: 4 anomalies
    Severity: 6/10
    Confidence: 68%
    Pattern: "Threshold breach - payment gateway issue"
    Time: 23ms

Scenario 5.3: Return Rate Surge
  Data: Daily return rate (%)
  Normal: 5-8%
  Anomaly: Spike to 25% (defective batch shipped)

  Result:
    [OK] Detected: 3 anomalies
    Severity: 7/10
    Confidence: 72%
    Pattern: "Elevated returns - product quality issue"
    Time: 24ms

Domain Summary:
  Detection Rate: 3/3 (100%)
  Avg Confidence: 71.1%
  Avg Severity: 6.7/10


OVERALL SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total Scenarios: 15
Detection Rate: 100% (15/15)
Avg Confidence: 75.6%
Avg Detection Time: 22ms
Avg Severity: 7.7/10

Top Performing Domain: DevOps (82.2% confidence)
Most Critical Domain: DevOps (8.7/10 avg severity)
Fastest Detection: Financial (18ms)

KEY INSIGHT: Same codebase, zero configuration changes,
             100% detection across all 5 domains.
```

**Talking Points:**
- "15 scenarios across 5 completely different industries"
- "100% detection rate - not a single missed anomaly"
- "Zero configuration changes between domains - truly universal"
- "DevOps has highest confidence (82.2%) - clearest signals"
- "Healthcare lower confidence (67.8%) - noisier data, appropriate caution"
- "Sub-25ms detection time - real-time capable"

---

## [07] Quick Reference: Architecture Decisions

**Use this for:** Technical interviews, design discussions

```
KEY ARCHITECTURE DECISIONS & RATIONALE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[1] Why 3 Agents Instead of 1 Model?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: Multi-agent consensus (3 specialists)
Alternative: Single GPT-5 Pro call

Rationale:
  âœ“ Inspired by Facilitair's 73% quality improvement
  âœ“ Error correction through consensus
  âœ“ Specialization: Each agent optimized for one task
  âœ“ Cross-validation: Agents check each other
  âœ“ Proven: +42.5% quality vs single-model baselines

Trade-offs:
  - Higher token cost (3x LLM calls)
  + Lower false positive rate (consensus)
  + Granular confidence (per-agent scores)


[2] Why Parallel Execution (asyncio)?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: asyncio.gather() for parallel agents
Alternative: Sequential execution

Rationale:
  âœ“ 3x speedup (0.8s vs 2.4s)
  âœ“ Agents are independent - no data dependencies
  âœ“ Real-time detection requirement (<1s)
  âœ“ Efficient I/O usage (network-bound, not CPU)

Implementation:
  tasks = [agent.analyze(context) for agent in agents]
  results = await asyncio.gather(*tasks)


[3] Why Confidence-Weighted Voting?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: weight = confidence Ã— historical_accuracy
Alternative: Equal weighting or majority vote

Rationale:
  âœ“ Agents have different accuracy (78%-92%)
  âœ“ Confidence reflects signal strength
  âœ“ Adaptive: Weights improve over time
  âœ“ Prevents overconfident but wrong agents

Formula:
  severity = Î£(agent_severity Ã— agent_weight) / Î£(weights)
  where weight = current_confidence Ã— historical_accuracy


[4] Why Autonomous Learning?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: Track performance, adjust weights
Alternative: Static thresholds

Rationale:
  âœ“ System improves with usage (62 detections â†’ +22% confidence)
  âœ“ No manual tuning required
  âœ“ Adapts to domain-specific patterns
  âœ“ Stores successful strategies for pattern matching

Storage:
  backend/cache/learning/
    â”œâ”€ agent_performance.json (accuracy tracking)
    â””â”€ successful_strategies.json (pattern library)


[5] Why StackAI Gateway?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: Route through StackAI flows
Alternative: Direct OpenAI API calls

Rationale:
  âœ“ Centralized model routing (switch models easily)
  âœ“ Deployed flows with optimized prompts
  âœ“ Cost tracking per agent
  âœ“ Automatic failover (if flow down, use direct API)

Trade-offs:
  - Network hop adds 50-100ms latency
  + Easier A/B testing of prompts
  + Better cost visibility


[6] Why Weave for Observability?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: Weave LLM tracing
Alternative: Manual logging or LangSmith

Rationale:
  âœ“ Sponsor integration (showcase value)
  âœ“ Nested traces (orchestrator â†’ agents)
  âœ“ Automatic token tracking
  âœ“ Prompt versioning
  âœ“ Minimal code changes (@weave.op() decorator)

Usage:
  WEAVE_ENABLED=true â†’ Full tracing
  WEAVE_ENABLED=false â†’ No overhead


[7] Why Senso RAG?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: Retrieve historical context before analysis
Alternative: Zero-shot detection only

Rationale:
  âœ“ Learn from past incidents (avoid repeats)
  âœ“ Provides Root Cause Agent with domain knowledge
  âœ“ Graceful degradation (optional, fails safely)
  âœ“ +15% accuracy improvement (with context vs without)

Flow:
  Query: "financial fraud spike"
  â†’ Senso returns: "Flash crash pattern 2024-09-15"
  â†’ Include in Root Cause Agent prompt


[8] Why CSV Format?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: timestamp,value CSV schema
Alternative: JSON or Parquet

Rationale:
  âœ“ Universal format (Excel, SQL, Python)
  âœ“ Simple for demos and testing
  âœ“ No schema overhead
  âœ“ Easy to generate synthetic data
  âœ“ 100KB files vs 500KB+ JSON

Schema:
  Required: 'value' column (numeric)
  Optional: 'timestamp' column (ISO 8601)


[9] Why Dataclasses?
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Decision: @dataclass for AnomalyContext, AgentFinding, Verdict
Alternative: Dicts or Pydantic

Rationale:
  âœ“ Type safety (mypy compatible)
  âœ“ Auto __init__, __repr__, __eq__
  âœ“ No external dependencies (stdlib)
  âœ“ Serializable with asdict()

Example:
  @dataclass
  class AnomalyVerdict:
      severity: int
      confidence: float
      summary: str
```

**Talking Points:**
- "Every architecture decision backed by data or proven patterns"
- "Multi-agent approach: +42.5% quality improvement (Facilitair research)"
- "Parallel execution: 3x speedup without added complexity"
- "Autonomous learning: +22% confidence improvement over 62 detections"
- "Graceful degradation: All integrations optional, fail safely"

---

## [08] Demo Script Reference

**Use this during:** Live demo, video recording

```
DEMO SCRIPT (5-7 minutes)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[0:00-0:30] INTRODUCTION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "Hi, I'm Blake. This is Anomaly Hunter - an autonomous
   data quality monitor that uses 3 AI agents to detect
   and investigate anomalies in real-time.

   It's built on Facilitair's proven multi-agent architecture
   and validated across 5 industries with 100% detection rate."

Show: README.md (scroll to badges)


[0:30-1:30] ARCHITECTURE WALKTHROUGH
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "Here's how it works. Three specialized agents run in parallel:

   1. Pattern Analyst (GPT-5 Pro) - Statistical z-score analysis
   2. Change Detective (Claude 4.5) - Time-series drift detection
   3. Root Cause Agent (Claude 4.5) - Hypothesis generation

   They synthesize findings using confidence-weighted voting,
   similar to Facilitair's Architect-Coder-Reviewer pipeline
   which achieved 73% quality pass rates."

Show: Diagram [01] or [02] from this file


[1:30-2:30] LIVE DETECTION: Financial Fraud
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "Let's detect some anomalies. I've prepared 4 datasets
   across different domains. First: financial fraud.

   100 transactions, normal range $20-$200. But we injected
   5 fraudulent charges between $850-$1250."

Commands:
  $ cd ~/Documents/AH_Demo_Data
  $ python3 /path/to/cli.py detect 1_financial_fraud.csv

Expected Output:
  Severity: 8/10
  Confidence: 87%
  Pattern: "87.2Ïƒ deviation - extreme fraud pattern"
  Time: ~1 second

Highlight:
  "87 sigma deviation - that's a smoking gun.
   100% confidence this is fraud."


[2:30-3:30] LIVE DETECTION: IoT Equipment Failure
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "Next: IoT manufacturing. Equipment vibration sensor.
   Normal is 1.2 mm/s. We simulated bearing wear - gradual
   degradation to 8-9 mm/s. This is subtle, not a spike."

Commands:
  $ python3 /path/to/cli.py detect 2_iot_equipment_failure.csv

Expected Output:
  Severity: 9/10
  Confidence: 83%
  Pattern: "Gradual drift + spike - bearing wear"

Highlight:
  "Change Detective caught the drift - 553% increase.
   This is predictive maintenance in action."


[3:30-4:30] AUTONOMOUS LEARNING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "Every detection improves the system. We've processed
   62 detections so far. The learning engine tracks
   which agents are most accurate and adjusts weights.

   Change Detective: 92% accuracy â†’ highest weight
   Pattern Analyst: 85% accuracy
   Root Cause: 78% accuracy

   Confidence improved +22% (34% relative) from initial
   detections to now."

Show: Diagram [03] or open:
  backend/cache/learning/agent_performance.json


[4:30-5:30] SPONSOR INTEGRATIONS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "This isn't just a demo - it's production-ready.
   9 sponsor integrations:

   â€¢ Weave: Full LLM observability (see every token)
   â€¢ Sentry: Error monitoring and alerting
   â€¢ Senso: RAG knowledge base (learns from history)
   â€¢ Redpanda: Real-time streaming to consumers
   â€¢ StackAI: Multi-model routing
   â€¢ TrueFoundry: ML platform deployment
   â€¢ ElevenLabs: Voice alerts for critical detections
   â€¢ Airia: Automated workflow responses

   All tested, all working."

Show: Diagram [04] or check_integrations output


[5:30-6:30] DOMAIN-AGNOSTIC VALIDATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "We validated this across 5 domains - 15 scenarios total.
   Same codebase, zero config changes.

   Financial: 80% confidence
   DevOps: 82% confidence
   IoT: 77% confidence
   E-Commerce: 71% confidence
   Healthcare: 68% confidence

   100% detection rate. Not a single missed anomaly."

Show: Diagram [06] or:
  evaluations/comprehensive_results.json


[6:30-7:00] CLOSING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Script:
  "That's Anomaly Hunter. Multi-agent architecture,
   autonomous learning, production-ready integrations,
   and validated across industries.

   Thanks for watching. Code is on GitHub, sponsors
   are linked in the README. Questions? Reach out!"

Show: README footer with links
```

**Demo Tips:**
- Have all datasets pre-loaded in ~/Documents/AH_Demo_Data/
- Run `check_integrations.py` before demo to verify all sponsors
- Keep Weave dashboard open in browser tab (show traces if time)
- Have comprehensive_results.json open for quick stats reference
- Practice timing - 7 minutes max, 5 minutes ideal

---

## Usage Guide

### For Demo Videos
1. Start with Diagram [01] (high-level overview)
2. Show Diagram [02] during technical deep-dive
3. Reference Diagram [04] when discussing sponsors
4. End with Diagram [06] for validation proof

### For Technical Interviews
1. Use Diagram [07] for architecture decision rationale
2. Show Diagram [03] for autonomous learning explanation
3. Walk through Diagram [05] for full data flow understanding

### For Investor Presentations
1. Focus on Diagram [01] (simple, clear)
2. Show Diagram [06] (domain validation = market potential)
3. Reference Diagram [04] (9 sponsors = ecosystem validation)

### For Documentation
- All diagrams embedded in README or docs/
- ASCII art renders in markdown viewers, IDEs, terminals
- Can be screenshot for slides or PDFs

---

**Version:** 1.0
**Last Updated:** 2024-10-21
**Total Diagrams:** 8
**Complexity:** Simple â†’ Detailed (progressive)
